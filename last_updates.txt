Last updates:

2022-11-15: first version

2023-01-04: bug fix in fxp_sum

2023-01-05: Multiplication now done not using longs, entirely with ints, so 
supporting systems where sizeof(long) == sizeof(int), but for now at the 
cost of performance, and some precision loss (but that precision loss gets 
solved later, see update end of Jan/2023 below).

2023-01-06: bugs fixed in new safe multiplication, also in the safe sum for 
a border case.

2023-01-08: new version with runtime-modifiable number of bits to use for 
the frac part. Fine-tuned all code, now all tests run with 0 warnings for 
any chosen number of frac bits. Tester checks different nums of frac bits.

2023-01-09: Default number of frac bits is set to 14. Beautified tester 
output organization.

2023-01-11: Using gcc's own built in to count leading zeros. Tester program 
now using long-doubles to better compare different implementations of the 
operations. Thanks to that, a few bugs exposed and fixed along the way.

2023-01-15: implemented fxp division using only ints (fxp_div) Basically a 
software-based implementation of binary division (tailored to fxp's.) 
Because of this, it is significantly slower: average execution time of 
first version is ~6x that of fxp_div_l. However it will work for systems in 
which sizeof(long) is not larger than sizeof(int).

2023-01-29: improved testing framework using long doubles, and refactored 
some utility functions related to testing and tracing in a separate file: 
fxp_aux.c.

2023-01-31: significant precision improvement in fxp_mul(), now offering 
pretty much the same precision as fxp_mul_l() while still only using ints, 
no longs. The calculation uses the distributive approach twice, now the 
second time within the frac part only.

2023-02-01: bug fixed in fxp_xtimes.c. After this fix, the true relative 
execution time of fxp_mul() is shown to be effectively ~6x that of 
fxp_mul_l(). This makes a lot of sense, as a similar ratio stands between 
fxp_div() and fxp_div_l(). Both * and / operations implemented using longs 
are then significantly faster (~6x) than the int-only implementations.

2023-02-09: log2_l implemented. Uses an algorithm that requires one 
multiplication (using longs) per mantissa bit, so simple to implement, but 
quite expensive. Likely will replace it with a more efficient one later. 
For now the relative execution time of one log2_l() calculation of an fxp 
is about ~18x that of adding two fxp's.

2023-02-10: BKM for logarithm calculation implemented: log2_bkm() Clearly 
faster than log2_l: ~28.5% the runtime: one BKM log calculation is about 
~5x the addition of two fxp's. The BKM calculation also has 30 bit-frac 
precision (log2_l's precision is max 29 frac bits). BKM can also compute 
the logarithms when the fxp config is using only 1 whole bit (log2_l 
requires at least 3 whole bits.) Tester requires relaxing the delta 
tolerance in this case. The only drawback of BKM is that it requires some 
more memory: needs a table of 32 ints with some pre-calculated log values

2023-02-11: Debugging implementations of log2, and exploring the largest 
errors incurred. Also moving these last updates out of the README and into
this separate file.

2023-02-14: lg2 implemented and debugged. 4 versions:
lg2():      BKM using only ints. Excellent accuracy, fast.
lg2_l():    BKM using longs. Excellent accuracy, fastest.
lg2_mul():  Uses multiplication, and only ints. This is the slowest, but
            requires no table of pre-calculated values like BKM does.
            Not as accurate as the BKM-based functions.
lg2_mul_l(): Uses multiplication and longs, no table of pre-calculated
            values required. Not as accurate as the BKM-based functions.

2023-02-15: Measuring execution times of the different lg2
implementations more accurately passing only + arguments.
Average ratio of their relative exec times using 8, 16, 24 and 28
frac bits. Are all relative to fxp_lg2 itself here (not to fxp_add()):
fxp_lg2:		1
fxp_lg2_l:		0.51x
fxp_lg2_mul_l:	1.54x
fxp_lg2_mul:	9.3x
fxp_lg2_mul() is quite the odd man out: at least using current
implementation of fxp_mul() (which takes ~6x the time of _mul_l()).
It takes fxp_lg2_mul() ~9x the time fxp_lg2() takes to run.
Almost an order of magnitude slower!
Only in some extremely memory-limited scenarios would it
make sense to be ok with such loss in speed, compared to just having
to hold the arrays of pre-calculated values in memory for the
BKM-based lg2, a total of only ~66 int values. And that could be
even cut in half by eliminating the _xtra array, so only ~33 int
values. Not processing those _xtra[] values would mean losing ultimate
precision, but it would make lg2 simpler and also faster actually.
So for now eliminating the lg2_mul() implementation. If worth
considering, it's the same as lg2_mul_l() after all, only the call
to  fxp_mul_l() in its loop would need to get replaced with a call
to fxp_mul().
Added some system info at the beginning of the outputs.
Added ln() and log10(), also tests for them.

2023-02-16: trying to get 128-bit precision for the long double
constants on an Intel-based pc. Only way seems to be to resort
to using quadmath.h, little program test_quad.c checks this.
Cleaning up comments. Also simplified the testing of lg10 and ln.

2023-02-18: separated the functions using longs into a separate
fxp_l.* files.  
A new file fxp_conv.c with utility conversion functions between 
fxp and float, double, and long double.
Adjusted code in all programs to use some variables as externals
from some of the other files.
Improved fxp_xtimes to show at the end the averages of configs
with 8, 12, 16, 20, 24, and 28 frac bits.

2023-02-19: removed macros MIN and MAX from fxp.h
Bug fix in the new fxp2ld conversion: it was using truncf() instead of
truncl().
Added tests for all roundtrip conversions, fxp -> floating-point ->
back to fxp.

2023-02-23:
Replacing #define statements with constant declarations in the 
program files.
Defining the transcendental constants with unsigned ints
Updated the 64 bit unsigned long versions of the transcendental 
constants with more accurate calculations (using 128 bit long doubles 
in Arm) down to the last bit rounded
Removing fxp_tconst.h

2023-02-25:
Writing a core multiplication function for two frac parts using the 
distributive scheme on its halves (words): mul_distrib(). This can be 
called from the fxp_mul() to compute pf3, but also after calculating 
a log2 or pow2 mantissa, to multiply it by the factors for base e or 
base 10 logarithms at full possible precision within ints, before any 
r-shifting. This way we avoid significant precision loss for those
functions.

2023-03-06:
Simplified fxp_mul calling mul_distrib() for pf3
Preliminaries for the new scheme to multiply mantissas by lg and pow 
factors at full precision.
Improved fxp_get_dec_frac() for the cases when
FXP_frac_mask is < fxp_frac_max_dec
Minor debuggin of division in one border case where it was returning 
FXP_UNDEF when it should have returned FXP_NEG_INF. This was related to 
the overflow check at the beginning of the division, which uses 
multiplication. Fox x = fxp(1), and y = 2 (so y = tiniest+1), FXP_MAX * y 
was exactly == x, yet the division was calculating x / y and returning 
FXP_UNDEF in the end (all one bits).

2023-03-07:
mul_distrib_l() implemented in fxp_l.c
fxp_pow2_l() implemented using mul_distrib_l()
Tests for it now run with zero warnings!

2023-03-12:
mul_distrib() implemented in fxp.c,
fxp_pow2() implemented using mul_distrib(), and
tests for it now also running with zero warnings

2023-03-13:
Calibrating lg2 against lg2_l making it also loop through all
FXP_INT_BITS iterations, then also rounding last mantissa bit
in lg2 exactly the same way lg2_l does.
Then testing lg2 with exact same argument right after each test of lg2_l,
now shows both with exact same result down to the very last bit.
(Between pow2_l vs. pow2 at least for now there are ocassional differences
in the very last bit, but this is always below the warning range anyway.)
General aux variables cleanup, removed a few not really needed
especially for lg2.
Variable names now more consistent between int vs. long implementations
of lg2 and pow2 functions.

2023-03-19:
Modified tester to use the more typical ordering of
"expected before actual" arguments in test_fxp().
Functions ln_l() and lg10_l() reimplemented by calling
lg2_x_factor_l(), which multiplies by the factors at their
full precision. This means that ln_l and lg10_l now have
the same "as good as it can ever get" accuracy as lg2_l!
(WDELTA_MAX lowered from 6 to 2, yet no warnings!)
Compacted the code that tests all logarithms and powers.

2023-03-20:
Separated print_<type>_as_bin() functions into print_as_bits.c
Fine tuning lg2_x_factor(), analogous to lg2_x_factor_l()
in fxp_l.c, but for ints only in fxp.c.
Digging into the correct shifts needed for a final negative
lg for all frac bit cases.
Special tests for lg2(x) for x in [0, k] with k < 1, which
would cause overflow because of not enough whole bits
for the result.
After that, also 0 warnings for lg2, ln, and lg10 even with
the lowered WDELTA_MAX, so same accuracy as the _l versions.
As far as accuracy, this completes all the logarithms.

2023-03-22:
Renamed variables in lg2_x_factor for more clarity.
Improving the VERBOSE printouts, and inspecting
in detail the ranges of inputs that trigger certain
running paths in lg2_x_factor.
Clean up of vars no longer used.

2023-03-23:
Made fxp_tconst.c show the unsigned fxp representations
for constants lg2(e) y lg2(10), both as uint and ulong.
They will be used as factors for calculation of exp() and
pow10() using pow2().
Renamed the tuple struct used for lg as cmtuple (will also
use it for pow).
Reimplemented pow2 using the intermediate tuple.

2023-03-25:
Fixed a bug in one corner case for which oddly enough 
our Actual value was correct, but the Expected one was
incorrect!
Using 31 frac bits, pow2_l(-tiniest) was returning
a correct result very close to but smaller than 1,
as expected, yet get_pow2_target(-tiniest) was incorrectly
returning +INF.
This problem was caused by how FXP_max_ld was initialized.
Now instead of initializing it from the max valid fractional
value, and checking if any actual value was > than that,
we now initialize FXP_max_ld as the first invalid + integer
minus half tiniest for the current FXP config, and we check
if any value is >= to it.
After this change, with 31 frac bits get_pow2_target(-tiniest)
now does return a value very close to but smaller than 1, as
expected, instead of +INF.

2023-03-27
exp_l() and pow10_l() implemented using pow2_l()
Debugged mul_distrib_l(): xbyb was being used before
initialization.
Simplified and unified the tuple variable names on fxp.c
and fxp_l.c

2023-03-29
Relative execution times for ln(), ln_l(), exp() and exp_l()
now also measured by fxp_xtimes.c

2023-03-31
Intermediate refactoring of pow2() in fxp.c, following the same
adjusments made in fxp_l.c implementing exp and pow10
as pow2 times the corresponding factor.

2023-04-02
Finishing implementation of exp() and pow10() using pow2().
Some border cases still pending for detailed testing and
debugging, i.e.: exp(14.999...) triggers assert, but only
when using 8 or 9 frac bits (???).

2023-04-03
Added rounding of the l-shifted fracs at the end in functions 
get_xc_as_tuple(_l), which helps minimizes frac precision loss 
for exp() and pow10() (a.k.a. the 'LoFi' power functions).

Finished testing the power function after identifying and adding 
tests for their 'kcrit' values, those which when used as their 
exponents can incurr in large warning-triggering deltas for 
certain frag bit configurations.

Modified tester to use a more relaxed WDELTA_MAX when including 
tests for the 'LoFi' power functions, while keeping a much more 
strict error tolerance when skipping them.

Added a summary list of warning counts per frac bit 
configurations at the end of the tester output.

2023-04-05
Implementing the emulation of longs using uints (calling struct
and file ulongy.) This abstraction not only simplifies the BKM-E/L 
implementations in fxp.c greatly (they can mirror the code in 
fxp_l.c almost line by line,) but more importantly, it also 
enables us to preserve long precision all the way through the 
intermediate calculations in fxp.c for all transcendental 
functions that are ultimately based on lg2 and pow2, that is: ln, 
exp, log10, pow10, powxy, and sqrt. With this, there will be no 
such thing as 'LoFi' precision for any of the int-only 
implementations of those functions, so they will all end up being 
exactly as accurate as their fxp_l.c counterparts.

2023-04-11
Continuing with emulation of longs.
Withholding the idea of reimplementing in Rust.

2023-04-17

Renaming the distributive multiplication functions (formerly 
'mul_distrib') as 'dmul'.

The distributive multiplication functions turned out to be quite 
critical and needed in several places once trying to offer 
ultimate precision for all fxp transcendental functions (ln, exp, 
powxy etc) when using only ints. Also depending on where the dmul 
functions are getting called from, different combinations of 
argument types and result types are needed, so separate 
implementations (so far 6) required to cover all use cases 
encountered:

Using only ints:
    uint x uint --> uint
    uint x uint --> ulongy
    ulongy x uint --> ulongy
    ulongy x ulongy --> ulongy
Using longs:
    ulong x uint --> ulong
    ulong x ulong --> ulong

Writing a separate tester for all of them: dmul_tester.c
Separate and not in fxp_tester because the dmul functions
are independent and agnostic of frac bits and fxp's.

2023-04-18

Finishing ulongy.c, and dmul_tester.c

2023-04-19

Refactoring code to make use of all the new
dmul functions.

2023-04-20
Debugged rshift in ulongy testing the refactored lg2_x_factor
and ln()

2023-04-22
Defined the new long double infinity thresholds
FXP_max_ldx = FXP_max_ld + "half tiniest"
FXP_min_ldx = FXP_min_ld - "half tiniest"
 
Problematic border case, pow2_l(-2*tiniest) when using 31 frac 
bits. Expected result was +infinity, but the actual value 
calculated was almost infinity, yet no quite there, just very 
close to or equal to FXP_MAX. Extra accuracy increasing the 
number of loops in bkm_emode to INT BITS + 3 does solve that 
issue for 31 bits, but then a problematic case remains for 30 
bits (?). This one, calculating pow2_l(1-tiniest), ended up 
with infinity vs. non-infinity the other way around: pow2_l 
returned infinity, but the expected long double was very close 
to but not quite >= the +infinity threshold.

2023-04-23

The overall problem of those cases described above is not 
related to any fxp calculation inaccuracy, but just to the way 
the tester is mishandling very close values around the 
infinity thresholds. It has been triggering asserts whenever 
some expected vs. actual difference involves infinite vs. 
non-infinite values. That is the actual problem.

The fact is: regardless of bit accuracy in use, and how 
extremely close to each other they are , e.g. well below the 
max delta, expected vs. actual values CAN STILL POTENTIALLY 
LAND ON DIFFERENT SIDES OF AN INFINITY THREASHOLD. AND THAT IS 
A PERFECTLY FINE RESULT THAT WE SHOULD STILL ASSESS AS "SAME". 
THE FACT THAT AN INFINITY THRESHOLD IS BETWEEN THEM DOESN'T 
REALLY DETRACT FROM THEIR CLOSENESS. The tester, however, so 
far has always triggered an assert whenever one of the values 
either expected or actual is finite, while the other is an 
infinity. This has been the real issue, not any of the fxp 
calculations.

Modified the assert logic so that when expected vs. actual 
land on different sides of one of the tester's long double 
infinity thresholds (e.g. FXP_max_ldx, or FXP_min_ldx), then 
an effective delta will still get computed between the 
non-infinity value (either the expected or the actual) and the 
corresponding infinity threshold. If that delta is still 
within the max allowed delta, then everything is fine. Those 
expected vs. actual are effectively so close that, for all 
practical purposes, they are still the 'same' value.

Besides now not triggering those asserts, the tester will
however count how many of these rare threshold cases are
encountered per frac bit configuration, and the final
report now includes these counts.

Modified function print_fxp and the tester, so that the long
double printouts of the exp vs. actual values are perfecly
aligned on the output, for easier comparison.

Logarithm tests done similarly to the pow tests, so as to 
eliminate redundancies.

2023-04-24

Optimizing pow2_l, no need to use dmul since if one of the 
operands is a 1 as it is the case here, then the result of the 
dmul will for sure end up identical to the other operand 
anyway. We just need to shift it properly.

Double checking every iteration step of pow2_l for a border
case, to make sure they match exactly the steps in the pow2
implementation in bkm.c, which uses long doubles.

2023-04-25

Tester output refinements, specially displaying the
long double values.

Adjusting exp_l and pow10_l. Finished testing them.

2023-04-26

Completed refactoring in fxp.c, now uses an emulation of 
unsigned longs with two uints in a struct (called "ulongy") 
to process logarithms and power functions. Thanks to this, 
there are no longer any "LoFi" power functions: even though 
exp and pow10 technically still use only ints, they are now 
exactly just as accurate as exp_l and pow10_l using longs.

2023-04-27
Tests ran perfectly on an Intel pc, but failed on a Raspberry PI (Arm).
The test that failed was lg10(largest). After deeper inspection,
found out there was a bug in my r-shift function for ulongys,
which did not manifest when running on the Intel cpu, go figure.
Fixed it. Then ran successfully also on the Raspberry Pi.
Generated output and xtimes from the Rasp Pi as well.


2023-04-28

Thinking about cleanest way to implement sqrt() and powxy() given the
already written code, I'm realizing my internal "xc" functions
(get_xc_as_tuple[_l]) have 3 parameters, which brings to mind some wise 
observations from the book "Clean Code": likely some of these arguments
ought to be wrapped into a class of their own, and likely the function
is directly dealing with more than one level of abstraction.

In my case, the arguments which ought to be wrapped into a class of their
own would be the second and third. Those are the factor C, and 
c_nwbits: how many bits in C are whole bits. The duo clearly constitutes
a missing abstraction: a sort of independent or "self-configured" fixed point
number.

This is not just a "bigger FXP," it also has its own independent 
fxp configuration, (it's own number of whole vs. frac bits,) independent of
the global fxp setting, and in fact it carries this independent configuration
within. So it's an FXP with significant superpowers, so to speak.
Calling it super_fxp then.

The elements in the table of logs are (or could be) basically also 
instances of this abstraction, not just plain simple u. longs or ulongys.
They are indeed "super FXP's" with their own independent configuration,
and using more bits than normal fxps. All in the table with the same
configuration, but still, one that is completely independent of the global
fxp configuration.

So planning to refactor the code with this abstraction in mind.


2023-05-03

Pinpointing where is the precision beyond that of int really making a 
difference, by zeroing-out the lowest bits wherever using longs. After this 
check, turns out the tuple_l with pong as an unsigned long is overkill; an 
unsigned int there will do.


2023-05-05

Log and pow functions in fxp_l now working and tested after the refactoring.


2023-05-06

Tricky halving of the tuple negative values returned from the lg2 functions. 
sqrt_l implemented. Testing it.

Depprecated function lim_frac in fxp_aux, no longer used after the 
refinements in handling values near infinity thresholds.


2023-05-07

Added rounding in the halving of tuples in sqrt_l -> results in zero 
warnings in all tests for sqrt.

Documented refactoring TODO's specially in the comment for 
fxp_pow2_wneg_tuple_l (pending abstraction issue with the tuple it needs as 
input.)
Made pong in the tuple in fxp be an unsigned int, since it's overkill
to have it as ulongy (see 2023-05-03). Then eliminated the tuple_l, since
fxp_l is now using the exact same tuple struct used by fxp.
Added measuring sqrt_l and sqrt to fxp_xtimes.

2023-05-08

Debugged initialization of ULONGY_ALL_ONES_RS1 in ulongy.h, which was
causing a least significant bit difference between final frac results
from pow10_l and pow10 in some specific random cases. This was enough
to trigger assert if WDELTA_MAX was 1.0, even if not for 1.01.
After this fix, reverting it to 1.0, and absolutely zero warnings.

Added super_fxp to fxp.c, refactored some of pow-related functions
to have super_fxp arguments, as in fxp_l.c

Minor optimization in ulongy bitwise_and apllied only on the hi uint 
when we now the lo will remain the same. This optimizes a bit get_xc and 
therefore the pow functions in general.

Optimizations for lg functions by lowering the FXP_lg2_maxloops from 
FXP_frac_bits + 1 to FXP_frac_bits, realizing still no warnings 
whatsoever occur. If lowering it to frac bits -1, then asserts do occur.

Also optimizing the maxloops to use in lg2_x_factor, lowering from 
FXP_INT_BITS to FXP_INT_BITS_M1 -> still no asserts. If lowering one 
more, then asserts do occur.

So far bkm_emode always running FXP_INT_BITS loops. And yes that must 
remain, lowering it by even one does brings asserts right away in sqrt.

Clean up of a few variables no longer used in fxp.c.


Pending:
Refactor fxp to also use super_fxp's as fxp_l is doing now.
Implement powxy_l() and powxy()
Implement trigonometric functions
Rewrite in Rust?
